# Generate the optimization report markdown file
# RAG 系统优化报告

本报告针对自建 RAG 系统（仓库：https://github.com/francisk/rag-wh40k）提出全面优化方案，涵盖文本切片、向量化数据上传、查询处理、答案生成、系统健壮性、性能与成本等方面，并附加其他可选优化方向。

---

## 1. 文本切片（Chunking）

- **基于 Token 的切片**  
  - 使用 `tiktoken` 或类似工具计算切片的最大 token 数，确保每个 chunk 在模型上下文窗口范围内。  
  - 优先在自然段落末、句号、Markdown 级标题处断句，避免破坏规则条目完整性。  
- **增强重叠（Overlap）与标签**  
  - 除常规重叠外，对“武器 Profile + 通用规则 + 特例规则”进行同组打包，或设置更大 overlap。  
  - 为每个 chunk 添加 `chunk_type`（如 `weapon_profile`、`weapon_rule`、`leader_ability`、`coverage_rule`）标签，便于检索与二次排序。  
- **特例条款合并**  
  - 对“特例/覆盖规则”做预处理，标记并合并到相关通用规则的 chunks 中，确保查询时能一并命中。

## 2. 上传向量化数据（Indexing & Ingestion）

- **Token 化与编码**  
  - 在上传前进行统一的 token 化与归一化，保留专有名词、数字+单位（如 `12寸`、`S4`、`T6`）不被清洗。  
- **Batching 与并发控制**  
  - 将切片按批次上传向量数据库，使用并发限制和重试机制，避免因大规模插入导致的超时或收费激增。  
- **Metadata 配置**  
  - 在向量索引中保留 `source_file`、`chunk_id`、`chunk_type`、`section_heading` 等元数据，便于后续混合检索与基于上下文的过滤。

## 3. 查询处理（Query Processing）

- **同义词与别名映射**  
  - 构建术语词典（如中英文对照 `Asurman = 阿苏曼`、“deep strike” = “深入打击”），在 `query_expander` 中进行动态替换与扩展。  
- **保留关键标点与数字**  
  - 在预处理阶段避免剥离关键符号，保留模型名称、数值表达式，以保证精确匹配。  
- **高级扩展策略**  
  - 对含多条件的问题（如单位组合、领导者能力）拆分子查询，分别检索后合并结果。  
- **拼写纠错与近似匹配**  
  - 集成拼写校验与模糊匹配算法，提升对用户输入中小错误的容错能力。

## 4. 答案生成（LLM Synthesis & Prompting）

- **严格的 Prompt 模板**  
  - 明确列出回答格式：  
    1. **提取**: 从检索到的 chunks 中获取相关属性。  
    2. **应用规则**: 若存在覆盖规则或附加效果，优先使用特例。  
    3. **计算**: 执行数值运算并给出结果。  
    4. **引用**: 在每条要点末尾插入 `filecite...`。  
- **Chain-of-Thought 指令化**  
  - 在提示中嵌入多步思考指导，强制 LLM 按顺序执行各环节，减少遗漏。  
- **分步调用或工具调用**  
  - 对复杂计算（如爆炸武器附加骰、模型数量乘积），可拆成中间工具或脚本函数，先行执行再返回给 LLM。

## 5. 系统健壮性（Reliability & Monitoring）

- **日志记录与可追溯性**  
  - 记录每次检索到的 chunks ID、相似度分数、最终 Prompt 内容及生成结果，便于审计与调优。  
- **错误处理与降级策略**  
  - 对检索失败、模型调用超时或结果不完整时，返回可替代的 fallback 策略或简易回答。  
- **自动化测试**  
  - 建立覆盖常见问题类型的测试集，定期回归测试，验证系统在版本迭代中的稳定性。

## 6. 性能与成本（Efficiency & Cost）

- **向量查询缓存**  
  - 对相似或重复的查询结果进行短期缓存，减少重复检索开销。  
- **Prompt 长度控制**  
  - 动态剪裁无关 chunk，仅传输必要上下文，降低 token 使用量和费用。  
- **并行与批量处理**  
  - 对批量问题评估或批量索引操作，使用并行化策略，提升吞吐量。  
- **模型配置优化**  
  - 衡量不同模型（如 `gpt-4o-mini` vs `gpt-4o-standard`）在精度与成本上的折中，选取最优组合。

---

## 其他可选优化方向

- **混合检索（Hybrid Search）**：结合 BM25、Elasticsearch 等关键字检索与向量检索，实现高召回与高精度。  
- **规则引擎集成**：对核心数值规则做引擎化封装，可配置且可单独测试，降低对 LLM 推理能力的依赖。  
- **安全与权限管理**：对索引数据和用户日志进行脱敏与访问控制，保证企业信息安全。  
- **界面与体验**：提供可视化检索界面，支持参数调整、上下文预览与引用跳转，提高可用性。  
- **CI/CD 与模型版本化**：对切片、索引、检索、生成等各模块纳入持续集成与部署流水线，保障系统一致性。

---

*报告生成日期：2025-06-17*


# Write report to a markdown file
file_path = '/mnt/data/RAG_优化报告.md'
with open(file_path, 'w', encoding='utf-8') as f:
    f.write(report_content)

file_path
